# -*- coding: utf-8 -*-
"""DataScience_StudentMarks_PythonQuestionsUsingNumPyPandas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15T__YfZWO_H2FRou4AozB0wF0bU6O71o

Data Science Student Marks Python Questions Using NumPy & Pandas
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("data_science_student_marks.csv")

tech_cols = ["sql_marks", "excel_marks", "python_marks", "power_bi_marks"]
df["tech_avg"] = df[tech_cols].mean(axis=1)

df.head()

"""1. What is the average, median, minimum, and maximum score for each subject?

Use Pandas (mean, median, min, max) and optionally NumPy equivalents.
"""

avg_excel = np.mean(df['excel_marks'])
avg_sql = np.mean(df['sql_marks'])
avg_pbi = np.mean(df['power_bi_marks'])
avg_py = np.mean(df['python_marks'])

max_excel = np.max(df['excel_marks'])
max_sql = np.max(df['sql_marks'])
max_pbi = np.max(df['power_bi_marks'])
max_py = np.max(df['python_marks'])

min_excel = np.min(df['excel_marks'])
min_sql = np.min(df['sql_marks'])
min_pbi = np.min(df['power_bi_marks'])
min_py = np.min(df['python_marks'])

med_excel = np.median(df['excel_marks'])
med_sql = np.median(df['sql_marks'])
med_pbi = np.median(df['power_bi_marks'])
med_py = np.median(df['python_marks'])

dict_excel = {avg_excel, max_excel, min_excel, med_excel}
dict_sql = {avg_sql, max_sql, min_sql, med_sql}
dict_pbi = {avg_pbi, max_pbi, min_pbi, med_pbi}
dict_py = {avg_py, max_py, min_py, med_py}

print(dict_excel)
print(dict_sql)
print(dict_pbi)
print(dict_py)

"""2. Which location has the highest average technical skill score?

Calculate a new tech_avg column using NumPy/Pandas row operations.
"""

techavg_max = np.max(df["tech_avg"])
print(techavg_max)

df[df['tech_avg']==techavg_max]['location']

"""3. What percentage of students scored above 90 in each subject?

Use boolean filtering + .sum() + division to compute percentages.
"""

#version 1 for all subjects combined
def studentsAbove90():
  student_count = 0
  df_count = len(df)
  for index, row in df.iterrows():
    if row['excel_marks']>90 and row['python_marks']>90 and row['power_bi_marks']>90 and row['sql_marks']>90:
      student_count = student_count + 1
  print(student_count)
  print(df_count)
  percent_students = student_count/df_count
  print(percent_students)
  return student_count, percent_students

#studentsAbove90()

#version 2 for individual subjects
student_excel_count = 0
student_python_count = 0
student_pbi_count = 0
student_sql_count = 0
df_count = len(df)

student_excel_count = np.sum(df['excel_marks'] > 90)
student_sql_count = np.sum(df['sql_marks'] > 90)
student_python_count = np.sum(df['python_marks'] > 90)
student_pbi_count = np.sum(df['power_bi_marks'] > 90)

perc_excel_90 = student_excel_count/df_count
perc_py_90 = student_python_count/df_count
perc_sql_90 = student_sql_count/df_count
perc_pbi_90 = student_pbi_count/df_count

print(perc_excel_90, perc_py_90, perc_sql_90, perc_pbi_90)

"""4. Which student has the most balanced skillset (lowest variance in scores)?

Use NumPyâ€™s np.var() applied across each row of subject columns.
"""

df['tech_var'] = np.var(df[tech_cols], axis=1)
#print(df.head())
min_var = np.min(df['tech_var'])
location_lowest_var = df[df['tech_var']==min_var]['location']
student_lowest_var = df[df['tech_var']==min_var]['student_id']
print('Lowest Variance:',min_var)
print('Location(s)', location_lowest_var)
print('Student(s)', student_lowest_var)

"""5. What is the correlation between all skill scores?

Use a Pandas .corr() matrix to identify relationships between SQL, Excel, Python, Power BI, and English.
"""

course_marks_cols = ['sql_marks', 'excel_marks', 'python_marks', 'power_bi_marks', 'english_marks']
#df2 = np.array(df[course_marks_cols])
#df3 = pd.DataFrame(df[course_marks_cols])
df_scores = df[course_marks_cols]
df_scores.corr().round(2)

"""6. What is the average age of students who scored above the overall mean in Python?

Use filtering (df[df['python_marks'] > df['python_marks'].mean()]) and basic aggregation.
"""

filtered_data = df[df['python_marks'] > df['python_marks'].mean()]
avg_age = np.mean(filtered_data['age'])
print(f'average age for python marks above the mean: {avg_age:.2f}')

"""7. What location has the highest variance in skill scores across subjects?

Use groupby(location) combined with .var() to compare skill variability by city.
"""

course_marks_cols = ['sql_marks', 'excel_marks', 'python_marks', 'power_bi_marks', 'english_marks']
#df['all_var'] = np.var(df[course_marks_cols], axis=1)
marks_variances = df.groupby('location')[course_marks_cols].var()
variance_sum = marks_variances.sum(axis=1)
max_varsum = np.max(variance_sum)
max_varsum_position = np.argmax(variance_sum)
location_highest_var = variance_sum.idxmax()

#print(marks_variances)
print(variance_sum)
print(max_varsum)
print(max_varsum_position)
print(location_highest_var)

print(f"The location with the highest overall skill variance is {location_highest_var}, with a variance score of {max_varsum:.2f}.")

"""ðŸ“ˆ 8. Linear Regression Question
8. Can we predict a studentâ€™s Python score using their other skill scores, age, and location?

You will use:

Pandas for selecting numeric features:
["sql_marks", "excel_marks", "power_bi_marks", "english_marks", "age"]

Drop the location column (since we are avoiding encoding)

Train a LinearRegression model using only numeric features

Evaluate using RÂ²

Interpret coefficients to determine which variables most influence Python performance
"""

import statsmodels.api as sm

num_cols = ['sql_marks', 'excel_marks', 'python_marks', 'power_bi_marks', 'english_marks', 'age']
df.drop('location', axis=1, inplace=True)

X = df[['sql_marks', 'excel_marks', 'python_marks', 'power_bi_marks', 'age']]
X = sm.add_constant(X)
y = df['english_marks']

model = sm.OLS(y, X).fit()
print(model.summary())

print(model.mse_total.round(2))
print(model.rsquared.round(2))
print(model.params.round(2))
print(model.pvalues.round(2))